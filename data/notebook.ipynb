{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb15c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterio import features\n",
    "import rasterio\n",
    "from shapely.geometry import shape\n",
    "import os\n",
    "\n",
    "input_folder = \"./raw/pr\"\n",
    "output_folder = \"./processed/pr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae90a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "nc_file_list = glob.glob(os.path.join(input_folder, \"*.nc\"))\n",
    "\n",
    "if nc_file_list:\n",
    "    # Open all files as a single dataset along the time dimension\n",
    "    combined_ds = xr.open_mfdataset(nc_file_list, combine='by_coords')\n",
    "    # Group by year (using the 'year' coordinate) and process each year once\n",
    "    for year, yearly_ds in combined_ds.groupby('time.year'):\n",
    "        \n",
    "        augmented_yearly_data = yearly_ds.max(dim='time', keep_attrs=True)\n",
    "        \n",
    "        # heavy_rainfall = (yearly_ds['pr'] > 20).sum(dim='time', keep_attrs=True)\n",
    "        \n",
    "        # Calculate wet_days and align coordinates to match other variables\n",
    "        # wet_days = (yearly_ds['pr'] > 5).sum(dim='time', keep_attrs=True)\n",
    "        \n",
    "        yearly_sum = yearly_ds['pr'].sum(dim='time', keep_attrs=True)\n",
    "        \n",
    "        \n",
    "        # rolling_5day_sum = yearly_ds['pr'].rolling(time=5, min_periods=5).sum()\n",
    "        # max_5day_sum = rolling_5day_sum.max(dim='time', keep_attrs=True)\n",
    "        \n",
    "        rolling_3day_sum = yearly_ds['pr'].rolling(time=3, min_periods=3).sum()\n",
    "        max_3day_sum = rolling_3day_sum.max(dim='time', keep_attrs=True)\n",
    "\n",
    "        # augmented_yearly_data['max_5day_sum'] = max_5day_sum\n",
    "        augmented_yearly_data['max_3day_sum'] = max_3day_sum\n",
    "        augmented_yearly_data['sum'] = yearly_sum\n",
    "        # augmented_yearly_data['over_20'] = heavy_rainfall\n",
    "        # augmented_yearly_data['wet_days'] = wet_days\n",
    "        \n",
    "        out_path = os.path.join(\n",
    "            output_folder,\n",
    "            f\"pr_year_{year}.nc\"\n",
    "        )\n",
    "        augmented_yearly_data.to_netcdf(out_path)\n",
    "    combined_ds.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe7b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all NetCDF files in the output_folder\n",
    "nc_files = glob.glob(os.path.join(output_folder, \"*.nc\"))\n",
    "\n",
    "# Open and merge all datasets along the 'time' dimension\n",
    "merged_ds = xr.open_mfdataset(nc_files, combine='nested', concat_dim='year')\n",
    "\n",
    "# Optionally, save the merged dataset to a new file\n",
    "merged_ds.to_netcdf(os.path.join(output_folder, \"merged.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ed3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pr = xr.open_dataset(os.path.join(output_folder, \"climate_data/merged.nc\"))\n",
    "\n",
    "rolling_period = 30\n",
    "\n",
    "rolling_pr_sum = merged_pr['sum'].rolling(year=rolling_period, center=True, min_periods=1).mean()\n",
    "# rolling_over_20 = merged_pr['over_20'].rolling(year=5, center=True, min_periods=1).mean()\n",
    "rolling_max_3day_sum = merged_pr['max_3day_sum'].rolling(year=rolling_period, center=True, min_periods=1).mean()\n",
    "# rolling_max_5day_sum = merged_pr['max_5day_sum'].rolling(year=5, center=True, min_periods=1).mean()\n",
    "rolling_pr = merged_pr['pr'].rolling(year=rolling_period, center=True, min_periods=1).mean()\n",
    "# rolling_wet_days = merged_pr['wet_days'].rolling(year=5, center=True, min_periods=1).mean()\n",
    "rolling_values = xr.Dataset({\n",
    "    'sum_rolling': rolling_pr_sum,\n",
    "    # 'over_20_rolling': rolling_over_20,\n",
    "    'max_3day_sum_rolling': rolling_max_3day_sum,\n",
    "    # 'max_5day_sum_rolling': rolling_max_5day_sum,\n",
    "    'pr_rolling': rolling_pr,\n",
    "    # 'wet_days_rolling': rolling_wet_days\n",
    "    })\n",
    "\n",
    "out_rolling_path = os.path.join(output_folder, \"rolling_values_10.nc\")\n",
    "rolling_values.to_netcdf(out_rolling_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e52dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_from_baseline(data, output, name, period=15):\n",
    "    first_period = data.isel(year=slice(0, period))\n",
    "    baseline_mean = first_period.mean(dim='year')\n",
    "    # Remove the first 15 years from rolling_values for further analysis\n",
    "\n",
    "    # Calculate the difference for each year compared to the baseline mean\n",
    "    change_from_baseline = data - baseline_mean\n",
    "\n",
    "    trimmed_change = change_from_baseline.isel(year=slice(15, None))\n",
    "\n",
    "    # Optionally, save the change dataset\n",
    "    change_path = os.path.join(output, name)\n",
    "    trimmed_change.to_netcdf(change_path)\n",
    "    \n",
    "change_from_baseline(rolling_values, output_folder, \"rolling_change_from_baseline.nc\", period=15)\n",
    "# change_from_baseline(merged_ds, output_folder, \"single_change_from_baseline_10.nc\", period=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77d8b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tif_to_geojson(tif_folder, geojson_folder):\n",
    "    changesYears = [35, 45, 55, 65, 75, 85]\n",
    "    absYears = [50, 60, 70, 80, 90, 100]\n",
    "    os.makedirs(geojson_folder, exist_ok=True)\n",
    "    tif_files = glob.glob(os.path.join(tif_folder, \"*.tif\"))\n",
    "    for tif_file in tif_files:\n",
    "        years = absYears if 'Absolute' in os.path.basename(tif_file) else changesYears\n",
    "        with rasterio.open(tif_file) as src:\n",
    "            # Try to get timebands from metadata (e.g., tags or band descriptions)\n",
    "            timebands = []\n",
    "            if src.count > 1:\n",
    "                timebands = [src.descriptions[i] if src.descriptions[i] else f\"band_{i+1}\" for i in range(src.count)]\n",
    "            else:\n",
    "                timeband = src.tags().get('timeband', None)\n",
    "                timebands = [timeband if timeband else \"unknown\"]\n",
    "\n",
    "            # Only keep timebands that match the years list\n",
    "            selected_indices = [i for i, tb in enumerate(timebands) if any(str(y) in str(tb) for y in years)]\n",
    "            for band_idx in selected_indices:\n",
    "                image = src.read(band_idx + 1)\n",
    "                mask = image != src.nodata\n",
    "                shapes_gen = features.shapes(image, mask=mask, transform=src.transform)\n",
    "                geoms = []\n",
    "                for geom, value in shapes_gen:\n",
    "                    if value != src.nodata:\n",
    "                        geoms.append({\n",
    "                            'geometry': shape(geom),\n",
    "                            'properties': {'value': value, 'timeband': timebands[band_idx]}\n",
    "                        })\n",
    "                gdf = gpd.GeoDataFrame.from_features(geoms, crs=src.crs)\n",
    "                geojson_path = os.path.join(\n",
    "                    geojson_folder,\n",
    "                    f\"{os.path.splitext(os.path.basename(tif_file))[0]}_{timebands[band_idx]}.geojson\"\n",
    "                )\n",
    "                gdf.to_file(geojson_path, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5397ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_to_geojson(os.path.join(output_folder, \"masked_data\"), os.path.join(output_folder, \"geojson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82960ffc",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
